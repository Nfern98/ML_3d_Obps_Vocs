{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaU5oSHgWpFG",
        "outputId": "dc3d7a0e-ebd9-43e1-a6f2-e029a836d5d1",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in ./unit/entorno/lib/python3.7/site-packages (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in ./unit/entorno/lib/python3.7/site-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.14.6 in ./unit/entorno/lib/python3.7/site-packages (from scikit-learn) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in ./unit/entorno/lib/python3.7/site-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in ./unit/entorno/lib/python3.7/site-packages (from scikit-learn) (1.7.3)\n",
            "Requirement already satisfied: openpyxl in ./unit/entorno/lib/python3.7/site-packages (3.1.3)\n",
            "Requirement already satisfied: et-xmlfile in ./unit/entorno/lib/python3.7/site-packages (from openpyxl) (1.1.0)\n",
            "Requirement already satisfied: xgboost in ./unit/entorno/lib/python3.7/site-packages (1.6.2)\n",
            "Requirement already satisfied: numpy in ./unit/entorno/lib/python3.7/site-packages (from xgboost) (1.21.6)\n",
            "Requirement already satisfied: scipy in ./unit/entorno/lib/python3.7/site-packages (from xgboost) (1.7.3)\n",
            "Requirement already satisfied: lightgbm in ./unit/entorno/lib/python3.7/site-packages (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in ./unit/entorno/lib/python3.7/site-packages (from lightgbm) (1.21.6)\n",
            "Requirement already satisfied: scipy in ./unit/entorno/lib/python3.7/site-packages (from lightgbm) (1.7.3)\n",
            "Requirement already satisfied: bayesian-optimization in ./unit/entorno/lib/python3.7/site-packages (1.4.3)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in ./unit/entorno/lib/python3.7/site-packages (from bayesian-optimization) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in ./unit/entorno/lib/python3.7/site-packages (from bayesian-optimization) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.9.0 in ./unit/entorno/lib/python3.7/site-packages (from bayesian-optimization) (1.21.6)\n",
            "Requirement already satisfied: colorama>=0.4.6 in ./unit/entorno/lib/python3.7/site-packages (from bayesian-optimization) (0.4.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in ./unit/entorno/lib/python3.7/site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in ./unit/entorno/lib/python3.7/site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.3.2)\n",
            "Requirement already satisfied: scikit-optimize in ./unit/entorno/lib/python3.7/site-packages (0.10.2)\n",
            "Requirement already satisfied: numpy>=1.20.3 in ./unit/entorno/lib/python3.7/site-packages (from scikit-optimize) (1.21.6)\n",
            "Requirement already satisfied: pyaml>=16.9 in ./unit/entorno/lib/python3.7/site-packages (from scikit-optimize) (23.5.8)\n",
            "Requirement already satisfied: scipy>=1.1.0 in ./unit/entorno/lib/python3.7/site-packages (from scikit-optimize) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in ./unit/entorno/lib/python3.7/site-packages (from scikit-optimize) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in ./unit/entorno/lib/python3.7/site-packages (from scikit-optimize) (1.3.2)\n",
            "Requirement already satisfied: packaging>=21.3 in ./unit/entorno/lib/python3.7/site-packages (from scikit-optimize) (24.0)\n",
            "Requirement already satisfied: PyYAML in ./unit/entorno/lib/python3.7/site-packages (from pyaml>=16.9->scikit-optimize) (6.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in ./unit/entorno/lib/python3.7/site-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.1.0)\n",
            "Requirement already satisfied: hyperopt in ./unit/entorno/lib/python3.7/site-packages (0.2.7)\n",
            "Requirement already satisfied: networkx>=2.2 in ./unit/entorno/lib/python3.7/site-packages (from hyperopt) (2.6.3)\n",
            "Requirement already satisfied: six in ./unit/entorno/lib/python3.7/site-packages (from hyperopt) (1.16.0)\n",
            "Requirement already satisfied: tqdm in ./unit/entorno/lib/python3.7/site-packages (from hyperopt) (4.63.0)\n",
            "Requirement already satisfied: numpy in ./unit/entorno/lib/python3.7/site-packages (from hyperopt) (1.21.6)\n",
            "Requirement already satisfied: cloudpickle in ./unit/entorno/lib/python3.7/site-packages (from hyperopt) (2.2.1)\n",
            "Requirement already satisfied: scipy in ./unit/entorno/lib/python3.7/site-packages (from hyperopt) (1.7.3)\n",
            "Requirement already satisfied: py4j in ./unit/entorno/lib/python3.7/site-packages (from hyperopt) (0.10.9.7)\n",
            "Requirement already satisfied: future in ./unit/entorno/lib/python3.7/site-packages (from hyperopt) (1.0.0)\n",
            "Requirement already satisfied: joblib in ./unit/entorno/lib/python3.7/site-packages (1.3.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn\n",
        "!pip install openpyxl\n",
        "!pip install xgboost\n",
        "!pip install lightgbm\n",
        "!pip install bayesian-optimization\n",
        "!pip install scikit-optimize\n",
        "!pip install hyperopt\n",
        "!pip install joblib\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "ALPy-eqmXdPo",
        "outputId": "d215f17a-0d82-40a3-f404-082cc9f890a8",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>proteina</th>\n",
              "      <th>id</th>\n",
              "      <th>atoms</th>\n",
              "      <th>bonds</th>\n",
              "      <th>dbonds</th>\n",
              "      <th>HBA1</th>\n",
              "      <th>HBA2</th>\n",
              "      <th>HBD</th>\n",
              "      <th>logP</th>\n",
              "      <th>MP</th>\n",
              "      <th>...</th>\n",
              "      <th>QSOgrant42</th>\n",
              "      <th>QSOgrant43</th>\n",
              "      <th>QSOgrant44</th>\n",
              "      <th>QSOgrant45</th>\n",
              "      <th>QSOgrant46</th>\n",
              "      <th>QSOgrant47</th>\n",
              "      <th>QSOgrant48</th>\n",
              "      <th>QSOgrant49</th>\n",
              "      <th>QSOgrant50</th>\n",
              "      <th>Binding_Affinity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CmedPBP4</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6110</td>\n",
              "      <td>407.1765</td>\n",
              "      <td>...</td>\n",
              "      <td>0.031452</td>\n",
              "      <td>0.030593</td>\n",
              "      <td>0.032004</td>\n",
              "      <td>0.026301</td>\n",
              "      <td>0.031368</td>\n",
              "      <td>0.032444</td>\n",
              "      <td>0.027974</td>\n",
              "      <td>0.029908</td>\n",
              "      <td>0.034341</td>\n",
              "      <td>7.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CpunPBP2</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6110</td>\n",
              "      <td>407.1765</td>\n",
              "      <td>...</td>\n",
              "      <td>0.031559</td>\n",
              "      <td>0.031934</td>\n",
              "      <td>0.032102</td>\n",
              "      <td>0.026964</td>\n",
              "      <td>0.029060</td>\n",
              "      <td>0.033730</td>\n",
              "      <td>0.031201</td>\n",
              "      <td>0.029511</td>\n",
              "      <td>0.032615</td>\n",
              "      <td>10.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CpunPBP5</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6110</td>\n",
              "      <td>407.1765</td>\n",
              "      <td>...</td>\n",
              "      <td>0.030126</td>\n",
              "      <td>0.031509</td>\n",
              "      <td>0.030460</td>\n",
              "      <td>0.027874</td>\n",
              "      <td>0.028269</td>\n",
              "      <td>0.031272</td>\n",
              "      <td>0.030974</td>\n",
              "      <td>0.032708</td>\n",
              "      <td>0.031396</td>\n",
              "      <td>9.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CsinGOBP1</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6110</td>\n",
              "      <td>407.1765</td>\n",
              "      <td>...</td>\n",
              "      <td>0.033718</td>\n",
              "      <td>0.033598</td>\n",
              "      <td>0.028898</td>\n",
              "      <td>0.025392</td>\n",
              "      <td>0.030858</td>\n",
              "      <td>0.032347</td>\n",
              "      <td>0.029792</td>\n",
              "      <td>0.030958</td>\n",
              "      <td>0.033562</td>\n",
              "      <td>12.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CsinGOBP2</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6110</td>\n",
              "      <td>407.1765</td>\n",
              "      <td>...</td>\n",
              "      <td>0.031523</td>\n",
              "      <td>0.031068</td>\n",
              "      <td>0.032233</td>\n",
              "      <td>0.026548</td>\n",
              "      <td>0.030795</td>\n",
              "      <td>0.031066</td>\n",
              "      <td>0.030422</td>\n",
              "      <td>0.029792</td>\n",
              "      <td>0.031829</td>\n",
              "      <td>30.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1453</th>\n",
              "      <td>CmedPBP4</td>\n",
              "      <td>252</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.3110</td>\n",
              "      <td>205.3128</td>\n",
              "      <td>...</td>\n",
              "      <td>0.031452</td>\n",
              "      <td>0.030593</td>\n",
              "      <td>0.032004</td>\n",
              "      <td>0.026301</td>\n",
              "      <td>0.031368</td>\n",
              "      <td>0.032444</td>\n",
              "      <td>0.027974</td>\n",
              "      <td>0.029908</td>\n",
              "      <td>0.034341</td>\n",
              "      <td>50.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1454</th>\n",
              "      <td>CsinGOBP1</td>\n",
              "      <td>252</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.3110</td>\n",
              "      <td>205.3128</td>\n",
              "      <td>...</td>\n",
              "      <td>0.033718</td>\n",
              "      <td>0.033598</td>\n",
              "      <td>0.028898</td>\n",
              "      <td>0.025392</td>\n",
              "      <td>0.030858</td>\n",
              "      <td>0.032347</td>\n",
              "      <td>0.029792</td>\n",
              "      <td>0.030958</td>\n",
              "      <td>0.033562</td>\n",
              "      <td>30.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1455</th>\n",
              "      <td>CsinGOBP2</td>\n",
              "      <td>252</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.3110</td>\n",
              "      <td>205.3128</td>\n",
              "      <td>...</td>\n",
              "      <td>0.031523</td>\n",
              "      <td>0.031068</td>\n",
              "      <td>0.032233</td>\n",
              "      <td>0.026548</td>\n",
              "      <td>0.030795</td>\n",
              "      <td>0.031066</td>\n",
              "      <td>0.030422</td>\n",
              "      <td>0.029792</td>\n",
              "      <td>0.031829</td>\n",
              "      <td>9.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1456</th>\n",
              "      <td>CsinGOBP1</td>\n",
              "      <td>253</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6558</td>\n",
              "      <td>249.5221</td>\n",
              "      <td>...</td>\n",
              "      <td>0.033718</td>\n",
              "      <td>0.033598</td>\n",
              "      <td>0.028898</td>\n",
              "      <td>0.025392</td>\n",
              "      <td>0.030858</td>\n",
              "      <td>0.032347</td>\n",
              "      <td>0.029792</td>\n",
              "      <td>0.030958</td>\n",
              "      <td>0.033562</td>\n",
              "      <td>24.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1457</th>\n",
              "      <td>CsinGOBP2</td>\n",
              "      <td>253</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6558</td>\n",
              "      <td>249.5221</td>\n",
              "      <td>...</td>\n",
              "      <td>0.031523</td>\n",
              "      <td>0.031068</td>\n",
              "      <td>0.032233</td>\n",
              "      <td>0.026548</td>\n",
              "      <td>0.030795</td>\n",
              "      <td>0.031066</td>\n",
              "      <td>0.030422</td>\n",
              "      <td>0.029792</td>\n",
              "      <td>0.031829</td>\n",
              "      <td>30.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1458 rows × 3057 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       proteina   id  atoms  bonds  dbonds  HBA1  HBA2  HBD    logP        MP  \\\n",
              "0      CmedPBP4    1     14     14       3     1     1    0  0.6110  407.1765   \n",
              "1      CpunPBP2    1     14     14       3     1     1    0  0.6110  407.1765   \n",
              "2      CpunPBP5    1     14     14       3     1     1    0  0.6110  407.1765   \n",
              "3     CsinGOBP1    1     14     14       3     1     1    0  0.6110  407.1765   \n",
              "4     CsinGOBP2    1     14     14       3     1     1    0  0.6110  407.1765   \n",
              "...         ...  ...    ...    ...     ...   ...   ...  ...     ...       ...   \n",
              "1453   CmedPBP4  252      8      7       0     2     1    1  0.3110  205.3128   \n",
              "1454  CsinGOBP1  252      8      7       0     2     1    1  0.3110  205.3128   \n",
              "1455  CsinGOBP2  252      8      7       0     2     1    1  0.3110  205.3128   \n",
              "1456  CsinGOBP1  253      9      9       3     1     1    0  0.6558  249.5221   \n",
              "1457  CsinGOBP2  253      9      9       3     1     1    0  0.6558  249.5221   \n",
              "\n",
              "      ...  QSOgrant42  QSOgrant43  QSOgrant44  QSOgrant45  QSOgrant46  \\\n",
              "0     ...    0.031452    0.030593    0.032004    0.026301    0.031368   \n",
              "1     ...    0.031559    0.031934    0.032102    0.026964    0.029060   \n",
              "2     ...    0.030126    0.031509    0.030460    0.027874    0.028269   \n",
              "3     ...    0.033718    0.033598    0.028898    0.025392    0.030858   \n",
              "4     ...    0.031523    0.031068    0.032233    0.026548    0.030795   \n",
              "...   ...         ...         ...         ...         ...         ...   \n",
              "1453  ...    0.031452    0.030593    0.032004    0.026301    0.031368   \n",
              "1454  ...    0.033718    0.033598    0.028898    0.025392    0.030858   \n",
              "1455  ...    0.031523    0.031068    0.032233    0.026548    0.030795   \n",
              "1456  ...    0.033718    0.033598    0.028898    0.025392    0.030858   \n",
              "1457  ...    0.031523    0.031068    0.032233    0.026548    0.030795   \n",
              "\n",
              "      QSOgrant47  QSOgrant48  QSOgrant49  QSOgrant50  Binding_Affinity  \n",
              "0       0.032444    0.027974    0.029908    0.034341              7.13  \n",
              "1       0.033730    0.031201    0.029511    0.032615             10.06  \n",
              "2       0.031272    0.030974    0.032708    0.031396              9.85  \n",
              "3       0.032347    0.029792    0.030958    0.033562             12.93  \n",
              "4       0.031066    0.030422    0.029792    0.031829             30.00  \n",
              "...          ...         ...         ...         ...               ...  \n",
              "1453    0.032444    0.027974    0.029908    0.034341             50.00  \n",
              "1454    0.032347    0.029792    0.030958    0.033562             30.00  \n",
              "1455    0.031066    0.030422    0.029792    0.031829              9.57  \n",
              "1456    0.032347    0.029792    0.030958    0.033562             24.11  \n",
              "1457    0.031066    0.030422    0.029792    0.031829             30.00  \n",
              "\n",
              "[1458 rows x 3057 columns]"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import openpyxl\n",
        "import matplotlib as pyplot\n",
        "\n",
        "df=pd.read_excel('/home/nfernandez/unit/dataset_unidos.xlsx')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "DAwXmAmHC2dP",
        "outputId": "0c2b25e1-f1ae-4ea3-812b-54f8b5ac0927",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>atoms</th>\n",
              "      <th>bonds</th>\n",
              "      <th>dbonds</th>\n",
              "      <th>HBA1</th>\n",
              "      <th>HBA2</th>\n",
              "      <th>HBD</th>\n",
              "      <th>logP</th>\n",
              "      <th>MP</th>\n",
              "      <th>MR_x</th>\n",
              "      <th>MW_x</th>\n",
              "      <th>...</th>\n",
              "      <th>QSOgrant42</th>\n",
              "      <th>QSOgrant43</th>\n",
              "      <th>QSOgrant44</th>\n",
              "      <th>QSOgrant45</th>\n",
              "      <th>QSOgrant46</th>\n",
              "      <th>QSOgrant47</th>\n",
              "      <th>QSOgrant48</th>\n",
              "      <th>QSOgrant49</th>\n",
              "      <th>QSOgrant50</th>\n",
              "      <th>Binding_Affinity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6110</td>\n",
              "      <td>407.1765</td>\n",
              "      <td>43.6530</td>\n",
              "      <td>172.13850</td>\n",
              "      <td>...</td>\n",
              "      <td>0.031452</td>\n",
              "      <td>0.030593</td>\n",
              "      <td>0.032004</td>\n",
              "      <td>0.026301</td>\n",
              "      <td>0.031368</td>\n",
              "      <td>0.032444</td>\n",
              "      <td>0.027974</td>\n",
              "      <td>0.029908</td>\n",
              "      <td>0.034341</td>\n",
              "      <td>7.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6110</td>\n",
              "      <td>407.1765</td>\n",
              "      <td>43.6530</td>\n",
              "      <td>172.13850</td>\n",
              "      <td>...</td>\n",
              "      <td>0.031559</td>\n",
              "      <td>0.031934</td>\n",
              "      <td>0.032102</td>\n",
              "      <td>0.026964</td>\n",
              "      <td>0.029060</td>\n",
              "      <td>0.033730</td>\n",
              "      <td>0.031201</td>\n",
              "      <td>0.029511</td>\n",
              "      <td>0.032615</td>\n",
              "      <td>10.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6110</td>\n",
              "      <td>407.1765</td>\n",
              "      <td>43.6530</td>\n",
              "      <td>172.13850</td>\n",
              "      <td>...</td>\n",
              "      <td>0.030126</td>\n",
              "      <td>0.031509</td>\n",
              "      <td>0.030460</td>\n",
              "      <td>0.027874</td>\n",
              "      <td>0.028269</td>\n",
              "      <td>0.031272</td>\n",
              "      <td>0.030974</td>\n",
              "      <td>0.032708</td>\n",
              "      <td>0.031396</td>\n",
              "      <td>9.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6110</td>\n",
              "      <td>407.1765</td>\n",
              "      <td>43.6530</td>\n",
              "      <td>172.13850</td>\n",
              "      <td>...</td>\n",
              "      <td>0.033718</td>\n",
              "      <td>0.033598</td>\n",
              "      <td>0.028898</td>\n",
              "      <td>0.025392</td>\n",
              "      <td>0.030858</td>\n",
              "      <td>0.032347</td>\n",
              "      <td>0.029792</td>\n",
              "      <td>0.030958</td>\n",
              "      <td>0.033562</td>\n",
              "      <td>12.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6110</td>\n",
              "      <td>407.1765</td>\n",
              "      <td>43.6530</td>\n",
              "      <td>172.13850</td>\n",
              "      <td>...</td>\n",
              "      <td>0.031523</td>\n",
              "      <td>0.031068</td>\n",
              "      <td>0.032233</td>\n",
              "      <td>0.026548</td>\n",
              "      <td>0.030795</td>\n",
              "      <td>0.031066</td>\n",
              "      <td>0.030422</td>\n",
              "      <td>0.029792</td>\n",
              "      <td>0.031829</td>\n",
              "      <td>30.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1453</th>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.3110</td>\n",
              "      <td>205.3128</td>\n",
              "      <td>21.3938</td>\n",
              "      <td>89.07154</td>\n",
              "      <td>...</td>\n",
              "      <td>0.031452</td>\n",
              "      <td>0.030593</td>\n",
              "      <td>0.032004</td>\n",
              "      <td>0.026301</td>\n",
              "      <td>0.031368</td>\n",
              "      <td>0.032444</td>\n",
              "      <td>0.027974</td>\n",
              "      <td>0.029908</td>\n",
              "      <td>0.034341</td>\n",
              "      <td>50.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1454</th>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.3110</td>\n",
              "      <td>205.3128</td>\n",
              "      <td>21.3938</td>\n",
              "      <td>89.07154</td>\n",
              "      <td>...</td>\n",
              "      <td>0.033718</td>\n",
              "      <td>0.033598</td>\n",
              "      <td>0.028898</td>\n",
              "      <td>0.025392</td>\n",
              "      <td>0.030858</td>\n",
              "      <td>0.032347</td>\n",
              "      <td>0.029792</td>\n",
              "      <td>0.030958</td>\n",
              "      <td>0.033562</td>\n",
              "      <td>30.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1455</th>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.3110</td>\n",
              "      <td>205.3128</td>\n",
              "      <td>21.3938</td>\n",
              "      <td>89.07154</td>\n",
              "      <td>...</td>\n",
              "      <td>0.031523</td>\n",
              "      <td>0.031068</td>\n",
              "      <td>0.032233</td>\n",
              "      <td>0.026548</td>\n",
              "      <td>0.030795</td>\n",
              "      <td>0.031066</td>\n",
              "      <td>0.030422</td>\n",
              "      <td>0.029792</td>\n",
              "      <td>0.031829</td>\n",
              "      <td>9.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1456</th>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6558</td>\n",
              "      <td>249.5221</td>\n",
              "      <td>27.2990</td>\n",
              "      <td>112.08500</td>\n",
              "      <td>...</td>\n",
              "      <td>0.033718</td>\n",
              "      <td>0.033598</td>\n",
              "      <td>0.028898</td>\n",
              "      <td>0.025392</td>\n",
              "      <td>0.030858</td>\n",
              "      <td>0.032347</td>\n",
              "      <td>0.029792</td>\n",
              "      <td>0.030958</td>\n",
              "      <td>0.033562</td>\n",
              "      <td>24.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1457</th>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6558</td>\n",
              "      <td>249.5221</td>\n",
              "      <td>27.2990</td>\n",
              "      <td>112.08500</td>\n",
              "      <td>...</td>\n",
              "      <td>0.031523</td>\n",
              "      <td>0.031068</td>\n",
              "      <td>0.032233</td>\n",
              "      <td>0.026548</td>\n",
              "      <td>0.030795</td>\n",
              "      <td>0.031066</td>\n",
              "      <td>0.030422</td>\n",
              "      <td>0.029792</td>\n",
              "      <td>0.031829</td>\n",
              "      <td>30.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1458 rows × 3055 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      atoms  bonds  dbonds  HBA1  HBA2  HBD    logP        MP     MR_x  \\\n",
              "0        14     14       3     1     1    0  0.6110  407.1765  43.6530   \n",
              "1        14     14       3     1     1    0  0.6110  407.1765  43.6530   \n",
              "2        14     14       3     1     1    0  0.6110  407.1765  43.6530   \n",
              "3        14     14       3     1     1    0  0.6110  407.1765  43.6530   \n",
              "4        14     14       3     1     1    0  0.6110  407.1765  43.6530   \n",
              "...     ...    ...     ...   ...   ...  ...     ...       ...      ...   \n",
              "1453      8      7       0     2     1    1  0.3110  205.3128  21.3938   \n",
              "1454      8      7       0     2     1    1  0.3110  205.3128  21.3938   \n",
              "1455      8      7       0     2     1    1  0.3110  205.3128  21.3938   \n",
              "1456      9      9       3     1     1    0  0.6558  249.5221  27.2990   \n",
              "1457      9      9       3     1     1    0  0.6558  249.5221  27.2990   \n",
              "\n",
              "           MW_x  ...  QSOgrant42  QSOgrant43  QSOgrant44  QSOgrant45  \\\n",
              "0     172.13850  ...    0.031452    0.030593    0.032004    0.026301   \n",
              "1     172.13850  ...    0.031559    0.031934    0.032102    0.026964   \n",
              "2     172.13850  ...    0.030126    0.031509    0.030460    0.027874   \n",
              "3     172.13850  ...    0.033718    0.033598    0.028898    0.025392   \n",
              "4     172.13850  ...    0.031523    0.031068    0.032233    0.026548   \n",
              "...         ...  ...         ...         ...         ...         ...   \n",
              "1453   89.07154  ...    0.031452    0.030593    0.032004    0.026301   \n",
              "1454   89.07154  ...    0.033718    0.033598    0.028898    0.025392   \n",
              "1455   89.07154  ...    0.031523    0.031068    0.032233    0.026548   \n",
              "1456  112.08500  ...    0.033718    0.033598    0.028898    0.025392   \n",
              "1457  112.08500  ...    0.031523    0.031068    0.032233    0.026548   \n",
              "\n",
              "      QSOgrant46  QSOgrant47  QSOgrant48  QSOgrant49  QSOgrant50  \\\n",
              "0       0.031368    0.032444    0.027974    0.029908    0.034341   \n",
              "1       0.029060    0.033730    0.031201    0.029511    0.032615   \n",
              "2       0.028269    0.031272    0.030974    0.032708    0.031396   \n",
              "3       0.030858    0.032347    0.029792    0.030958    0.033562   \n",
              "4       0.030795    0.031066    0.030422    0.029792    0.031829   \n",
              "...          ...         ...         ...         ...         ...   \n",
              "1453    0.031368    0.032444    0.027974    0.029908    0.034341   \n",
              "1454    0.030858    0.032347    0.029792    0.030958    0.033562   \n",
              "1455    0.030795    0.031066    0.030422    0.029792    0.031829   \n",
              "1456    0.030858    0.032347    0.029792    0.030958    0.033562   \n",
              "1457    0.030795    0.031066    0.030422    0.029792    0.031829   \n",
              "\n",
              "      Binding_Affinity  \n",
              "0                 7.13  \n",
              "1                10.06  \n",
              "2                 9.85  \n",
              "3                12.93  \n",
              "4                30.00  \n",
              "...                ...  \n",
              "1453             50.00  \n",
              "1454             30.00  \n",
              "1455              9.57  \n",
              "1456             24.11  \n",
              "1457             30.00  \n",
              "\n",
              "[1458 rows x 3055 columns]"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df.drop(['proteina', 'id'\n",
        "              #'AA Sequence W/O signal peptide',\n",
        "              #'Compound Name'\n",
        "              #'Compound_Protein'\n",
        "              ], axis=1)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "z8lG8gFxtKJB",
        "outputId": "73db2e23-dbc1-4e41-bb03-b616febdf9e8",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>atoms</th>\n",
              "      <th>bonds</th>\n",
              "      <th>dbonds</th>\n",
              "      <th>HBA1</th>\n",
              "      <th>HBA2</th>\n",
              "      <th>HBD</th>\n",
              "      <th>logP</th>\n",
              "      <th>MP</th>\n",
              "      <th>MR_x</th>\n",
              "      <th>MW_x</th>\n",
              "      <th>...</th>\n",
              "      <th>QSOgrant42</th>\n",
              "      <th>QSOgrant43</th>\n",
              "      <th>QSOgrant44</th>\n",
              "      <th>QSOgrant45</th>\n",
              "      <th>QSOgrant46</th>\n",
              "      <th>QSOgrant47</th>\n",
              "      <th>QSOgrant48</th>\n",
              "      <th>QSOgrant49</th>\n",
              "      <th>QSOgrant50</th>\n",
              "      <th>Binding_Affinity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1458.000000</td>\n",
              "      <td>1458.000000</td>\n",
              "      <td>1458.000000</td>\n",
              "      <td>1458.000000</td>\n",
              "      <td>1458.000000</td>\n",
              "      <td>1458.000000</td>\n",
              "      <td>1458.000000</td>\n",
              "      <td>1458.000000</td>\n",
              "      <td>1458.000000</td>\n",
              "      <td>1458.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1458.000000</td>\n",
              "      <td>1458.000000</td>\n",
              "      <td>1458.000000</td>\n",
              "      <td>1458.000000</td>\n",
              "      <td>1458.000000</td>\n",
              "      <td>1458.000000</td>\n",
              "      <td>1458.000000</td>\n",
              "      <td>1458.000000</td>\n",
              "      <td>1458.000000</td>\n",
              "      <td>1458.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>13.501372</td>\n",
              "      <td>12.829904</td>\n",
              "      <td>1.843621</td>\n",
              "      <td>1.560357</td>\n",
              "      <td>1.211248</td>\n",
              "      <td>0.331962</td>\n",
              "      <td>0.653345</td>\n",
              "      <td>394.551428</td>\n",
              "      <td>41.336583</td>\n",
              "      <td>164.241769</td>\n",
              "      <td>...</td>\n",
              "      <td>0.032186</td>\n",
              "      <td>0.031953</td>\n",
              "      <td>0.030656</td>\n",
              "      <td>0.026647</td>\n",
              "      <td>0.030809</td>\n",
              "      <td>0.032175</td>\n",
              "      <td>0.029518</td>\n",
              "      <td>0.030757</td>\n",
              "      <td>0.031695</td>\n",
              "      <td>17.055089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>4.271700</td>\n",
              "      <td>4.232098</td>\n",
              "      <td>1.214290</td>\n",
              "      <td>1.113710</td>\n",
              "      <td>0.901054</td>\n",
              "      <td>0.481169</td>\n",
              "      <td>0.459521</td>\n",
              "      <td>141.156299</td>\n",
              "      <td>13.558114</td>\n",
              "      <td>54.355682</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001093</td>\n",
              "      <td>0.001499</td>\n",
              "      <td>0.001069</td>\n",
              "      <td>0.001509</td>\n",
              "      <td>0.001167</td>\n",
              "      <td>0.000941</td>\n",
              "      <td>0.001032</td>\n",
              "      <td>0.001068</td>\n",
              "      <td>0.001259</td>\n",
              "      <td>28.458075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.230700</td>\n",
              "      <td>68.437600</td>\n",
              "      <td>8.421800</td>\n",
              "      <td>41.028740</td>\n",
              "      <td>...</td>\n",
              "      <td>0.029326</td>\n",
              "      <td>0.028764</td>\n",
              "      <td>0.028186</td>\n",
              "      <td>0.023186</td>\n",
              "      <td>0.027799</td>\n",
              "      <td>0.028782</td>\n",
              "      <td>0.027330</td>\n",
              "      <td>0.028088</td>\n",
              "      <td>0.028221</td>\n",
              "      <td>0.160000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>10.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.311000</td>\n",
              "      <td>263.519000</td>\n",
              "      <td>31.491000</td>\n",
              "      <td>120.107000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.031542</td>\n",
              "      <td>0.030906</td>\n",
              "      <td>0.029837</td>\n",
              "      <td>0.025502</td>\n",
              "      <td>0.030065</td>\n",
              "      <td>0.031304</td>\n",
              "      <td>0.028812</td>\n",
              "      <td>0.029953</td>\n",
              "      <td>0.030676</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>14.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.720200</td>\n",
              "      <td>373.248100</td>\n",
              "      <td>40.851800</td>\n",
              "      <td>161.135740</td>\n",
              "      <td>...</td>\n",
              "      <td>0.032275</td>\n",
              "      <td>0.031821</td>\n",
              "      <td>0.030644</td>\n",
              "      <td>0.026362</td>\n",
              "      <td>0.030769</td>\n",
              "      <td>0.032248</td>\n",
              "      <td>0.029420</td>\n",
              "      <td>0.030746</td>\n",
              "      <td>0.031400</td>\n",
              "      <td>10.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.959900</td>\n",
              "      <td>525.059200</td>\n",
              "      <td>53.823800</td>\n",
              "      <td>208.170600</td>\n",
              "      <td>...</td>\n",
              "      <td>0.032889</td>\n",
              "      <td>0.033330</td>\n",
              "      <td>0.031488</td>\n",
              "      <td>0.027819</td>\n",
              "      <td>0.031638</td>\n",
              "      <td>0.032856</td>\n",
              "      <td>0.030243</td>\n",
              "      <td>0.031528</td>\n",
              "      <td>0.032578</td>\n",
              "      <td>20.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>30.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.078200</td>\n",
              "      <td>718.594800</td>\n",
              "      <td>82.200400</td>\n",
              "      <td>368.235680</td>\n",
              "      <td>...</td>\n",
              "      <td>0.035233</td>\n",
              "      <td>0.034475</td>\n",
              "      <td>0.032943</td>\n",
              "      <td>0.032618</td>\n",
              "      <td>0.033147</td>\n",
              "      <td>0.034071</td>\n",
              "      <td>0.033125</td>\n",
              "      <td>0.034123</td>\n",
              "      <td>0.034451</td>\n",
              "      <td>471.560000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 3055 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             atoms        bonds       dbonds         HBA1         HBA2  \\\n",
              "count  1458.000000  1458.000000  1458.000000  1458.000000  1458.000000   \n",
              "mean     13.501372    12.829904     1.843621     1.560357     1.211248   \n",
              "std       4.271700     4.232098     1.214290     1.113710     0.901054   \n",
              "min       4.000000     3.000000     0.000000     0.000000     0.000000   \n",
              "25%      10.000000     9.000000     1.000000     1.000000     1.000000   \n",
              "50%      14.000000    13.000000     2.000000     2.000000     1.000000   \n",
              "75%      17.000000    16.000000     3.000000     2.000000     2.000000   \n",
              "max      30.000000    31.000000     7.000000    11.000000     9.000000   \n",
              "\n",
              "               HBD         logP           MP         MR_x         MW_x  ...  \\\n",
              "count  1458.000000  1458.000000  1458.000000  1458.000000  1458.000000  ...   \n",
              "mean      0.331962     0.653345   394.551428    41.336583   164.241769  ...   \n",
              "std       0.481169     0.459521   141.156299    13.558114    54.355682  ...   \n",
              "min       0.000000    -1.230700    68.437600     8.421800    41.028740  ...   \n",
              "25%       0.000000     0.311000   263.519000    31.491000   120.107000  ...   \n",
              "50%       0.000000     0.720200   373.248100    40.851800   161.135740  ...   \n",
              "75%       1.000000     0.959900   525.059200    53.823800   208.170600  ...   \n",
              "max       2.000000     3.078200   718.594800    82.200400   368.235680  ...   \n",
              "\n",
              "        QSOgrant42   QSOgrant43   QSOgrant44   QSOgrant45   QSOgrant46  \\\n",
              "count  1458.000000  1458.000000  1458.000000  1458.000000  1458.000000   \n",
              "mean      0.032186     0.031953     0.030656     0.026647     0.030809   \n",
              "std       0.001093     0.001499     0.001069     0.001509     0.001167   \n",
              "min       0.029326     0.028764     0.028186     0.023186     0.027799   \n",
              "25%       0.031542     0.030906     0.029837     0.025502     0.030065   \n",
              "50%       0.032275     0.031821     0.030644     0.026362     0.030769   \n",
              "75%       0.032889     0.033330     0.031488     0.027819     0.031638   \n",
              "max       0.035233     0.034475     0.032943     0.032618     0.033147   \n",
              "\n",
              "        QSOgrant47   QSOgrant48   QSOgrant49   QSOgrant50  Binding_Affinity  \n",
              "count  1458.000000  1458.000000  1458.000000  1458.000000       1458.000000  \n",
              "mean      0.032175     0.029518     0.030757     0.031695         17.055089  \n",
              "std       0.000941     0.001032     0.001068     0.001259         28.458075  \n",
              "min       0.028782     0.027330     0.028088     0.028221          0.160000  \n",
              "25%       0.031304     0.028812     0.029953     0.030676          4.000000  \n",
              "50%       0.032248     0.029420     0.030746     0.031400         10.600000  \n",
              "75%       0.032856     0.030243     0.031528     0.032578         20.100000  \n",
              "max       0.034071     0.033125     0.034123     0.034451        471.560000  \n",
              "\n",
              "[8 rows x 3055 columns]"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-ewRwqdcyxJ",
        "outputId": "46413ac9-3766-4329-9946-7656d88d5d20",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1458 entries, 0 to 1457\n",
            "Columns: 3055 entries, atoms to Binding_Affinity\n",
            "dtypes: float64(2800), int64(255)\n",
            "memory usage: 34.0 MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_Q42Nzn1QmV",
        "outputId": "7f9c722b-ab1f-4cc3-b615-cc70dd9f1688",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler, RobustScaler, PowerTransformer, QuantileTransformer, MaxAbsScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import cross_val_predict, KFold, train_test_split, cross_val_score\n",
        "from sklearn.metrics import mean_squared_error, r2_score, roc_auc_score, confusion_matrix, roc_curve, auc, RocCurveDisplay, ConfusionMatrixDisplay, mean_absolute_error, mean_absolute_percentage_error\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "import joblib\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rYjiiRE020SV",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "descriptors_matrix = df.iloc[:, :-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rVreODTUWIjg",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "df_transform = df.copy()\n",
        "df_tranform = df[['Binding_Affinity']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jyGVTFmB3_QJ",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "X = descriptors_matrix\n",
        "y = df_tranform['Binding_Affinity']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAz4FkqCtpZ0",
        "outputId": "ba78c43f-55f4-4838-90a8-48b93cd0b21b",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Forma de X (variables independientes): (1458, 3054)\n",
            "Forma de y (variable dependiente): (1458,)\n"
          ]
        }
      ],
      "source": [
        "print(f'Forma de X (variables independientes): {X.shape}')\n",
        "print(f'Forma de y (variable dependiente): {y.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vdTCGqJph9f",
        "outputId": "0cbcae1e-1cb8-4baf-a055-dc8bf29a6bb8",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((1166, 3054), (292, 3054), (1166,), (292,))"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seed = 42  #Semilla\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
        "\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KZfXKwy32SU7",
        "outputId": "95dc2047-d31c-481b-98ef-2bc9e97a2f8a",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((1166, 3054), (292, 3054))"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_train_df = pd.DataFrame(X_train, columns=descriptors_matrix.columns)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_test = scaler.fit_transform(X_test)\n",
        "X_test_df = pd.DataFrame(X_test, columns=descriptors_matrix.columns)\n",
        "\n",
        "X_train.shape, X_test.shape\n",
        "#scaler = StandardScaler()\n",
        "#normalized_descriptors = scaler.fit_transform(descriptors_matrix)\n",
        "#normalized_descriptors_df = pd.DataFrame(normalized_descriptors, columns=descriptors_matrix.columns)\n",
        "\n",
        "#scalermm = MinMaxScaler()\n",
        "#normalized_descriptors1 = scalermm.fit_transform(descriptors_matrix)\n",
        "#normalized_descriptors_df1 = pd.DataFrame(normalized_descriptors1, columns=descriptors_matrix.columns)\n",
        "\n",
        "#scalerMm = MinMaxScaler(feature_range=(-1, 1))\n",
        "#normalized_descriptors2 = scalerMm.fit_transform(descriptors_matrix)\n",
        "#normalized_descriptors_df2 = pd.DataFrame(normalized_descriptors2, columns=descriptors_matrix.columns)\n",
        "\n",
        "#scaler = StandardScaler()\n",
        "#scaler = RobustScaler()\n",
        "#transformer = PowerTransformer(method='yeo-johnson')\n",
        "#transformer = QuantileTransformer(output_distribution='normal')\n",
        "#scaler = make_pipeline(transformer, StandardScaler())\n",
        "#scaler = MaxAbsScaler()\n",
        "#scaler = MinMaxScaler()\n",
        "#normalized_descriptors = scaler.fit_transform(descriptors_matrix)\n",
        "#normalized_descriptors_df = pd.DataFrame(normalized_descriptors, columns=descriptors_matrix.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIz1VvCXVctU",
        "outputId": "6fe076c1-a25f-49e5-ea5c-3c2360a50c8d",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((1166,), (292,))"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "y_train = np.array([-np.log10(ki / 1e9) for ki in y_train])\n",
        "y_train_df = pd.DataFrame(y_train, columns=['Affinity Train'])\n",
        "\n",
        "y_test = np.array([-np.log10(ki / 1e9) for ki in y_test])\n",
        "y_test_df = pd.DataFrame(y_test, columns=['Affinity Test'])\n",
        "\n",
        "y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZx65QJHKPaF"
      },
      "source": [
        "# ML\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "m9UyYexOd0zQ",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
        "from hyperopt.pyll.base import scope\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import cross_val_score, KFold, cross_validate\n",
        "#from sklearn.datasets import load_boston\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.metrics import make_scorer, mean_squared_error, r2_score, mean_absolute_error # Import make_scorer\n",
        "from sklearn.linear_model import BayesianRidge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qWJYec2XiT_T",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# Definir los \"scorers\" para las métricas\n",
        "scoring = {\n",
        "    'rmse': make_scorer(mean_squared_error, squared=False),  # RMSE\n",
        "    'r2': make_scorer(r2_score),  # R²\n",
        "    'mae': make_scorer(mean_absolute_error)  # MAE\n",
        "}\n",
        "\n",
        "def objective_bayesian(params):\n",
        "    model = BayesianRidge(\n",
        "        alpha_1=params['alpha_1'],\n",
        "        alpha_2=params['alpha_2'],\n",
        "        lambda_1=params['lambda_1'],\n",
        "        lambda_2=params['lambda_2'],\n",
        "        max_iter=int(params['max_iter']),\n",
        "        tol=params['tol'],\n",
        "        fit_intercept=True\n",
        "    )\n",
        "\n",
        "    # Parámetros que se imprimen en cada iteración\n",
        "    alp1, alp2 = params['alpha_1'], params['alpha_2']\n",
        "    lamb1, lamb2 = params['lambda_1'], params['lambda_2']\n",
        "    tol_v = params['tol']\n",
        "    iter_v = int(params['max_iter'])\n",
        "\n",
        "    # Validación cruzada\n",
        "    kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "    scoring = {'rmse': 'neg_root_mean_squared_error', 'r2': 'r2', 'mae': 'neg_mean_absolute_error'}\n",
        "    cv_results = cross_validate(model, X_train, y_train, cv=kfold, scoring=scoring, return_train_score=False)\n",
        "\n",
        "    # Calcular métricas promedio\n",
        "    mean_rmse = -np.mean(cv_results['test_rmse'])  # Convertir RMSE a positivo\n",
        "    mean_r2 = np.mean(cv_results['test_r2'])\n",
        "    mean_mae = -np.mean(cv_results['test_mae'])  # Convertir MAE a positivo\n",
        "    mean_r2_n = -mean_r2  # Minimizar el R² negativo\n",
        "\n",
        "    print(f\"RMSE: {mean_rmse}, R² : {mean_r2}, MAE: {mean_mae} ;\\n\\t PARAMS; alpha_1: {alp1}, alpha_2: {alp2}, lambda_1: {lamb1}, lambda_2: {lamb2}, tol: {tol_v}, max_iter: {iter_v}\")\n",
        "    print(\"-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    return {'loss': mean_r2_n, 'status': STATUS_OK, 'rmse': mean_rmse, 'r2': mean_r2, 'mae': mean_mae}\n",
        "\n",
        "# Espacio de búsqueda de hiperparámetros\n",
        "space_bayesian = {\n",
        "    'alpha_1': hp.loguniform('alpha_1', np.log(1e-8), np.log(1e-0)),\n",
        "    'alpha_2': hp.loguniform('alpha_2', np.log(1e-8), np.log(1e-0)),\n",
        "    'lambda_1': hp.loguniform('lambda_1', np.log(1e-8), np.log(1e-0)),\n",
        "    'lambda_2': hp.loguniform('lambda_2', np.log(1e-8), np.log(1e-0)),\n",
        "    'tol': hp.loguniform('tol', np.log(1.0), np.log(2.0)),\n",
        "    'max_iter': hp.quniform('max_iter', 100, 1000, 25)  # Ajustado para mantenerlo razonable\n",
        "}\n",
        "\n",
        "def objective_xgb(params):\n",
        "    # Convertir los parámetros a enteros donde sea necesario\n",
        "    params['n_estimators'] = int(params['n_estimators'])\n",
        "    params['max_depth'] = int(params['max_depth'])\n",
        "    params['min_child_weight'] = int(params['min_child_weight'])\n",
        "\n",
        "    model = XGBRegressor(**params,\n",
        "                         booster='gbtree',\n",
        "                         objective='reg:squarederror',\n",
        "                         eval_metric='rmse',\n",
        "                         tree_method='hist',\n",
        "                         scale_pos_weight=1,\n",
        "                         n_jobs=-1,\n",
        "                         random_state=seed,\n",
        "                         seed=seed)\n",
        "\n",
        "    est = int(params['n_estimators'])\n",
        "    lg_rt = params['learning_rate']\n",
        "    max_dep = int(params['max_depth'])\n",
        "    min_Ch_w = int(params['min_child_weight'])\n",
        "    subs = params['subsample']\n",
        "    col_by = params['colsample_bytree']\n",
        "    alp = params['alpha']\n",
        "    lamb = params['reg_lambda']\n",
        "    gam = params['gamma']\n",
        "\n",
        "    # kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "\n",
        "\n",
        "    # score = -np.mean(cross_val_score(model, X_train, y_train, cv=kfold,\n",
        "    #                                 scoring='r2', n_jobs=-1))\n",
        "\n",
        "    # print(\"Score CV XGBRegressor: \", score)\n",
        "\n",
        "    # return {'loss': score, 'status': STATUS_OK}\n",
        "\n",
        "    # Validación cruzada\n",
        "    kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "\n",
        "    # Evaluar usando cross_validate para obtener RMSE, R² y MAE\n",
        "    cv_results = cross_validate(model, X_train, y_train, cv=kfold, scoring=scoring, return_train_score=False)\n",
        "\n",
        "    # Calcular la media de cada métrica\n",
        "    #mean_rmse = -np.mean(cv_results['test_rmse'])  # Negativo porque Hyperopt minimiza\n",
        "    mean_rmse = np.mean(cv_results['test_rmse'])  # Negativo porque Hyperopt minimiza\n",
        "    mean_r2 = np.mean(cv_results['test_r2'])\n",
        "    mean_r2_n = -np.mean(cv_results['test_r2'])\n",
        "    mean_mae = np.mean(cv_results['test_mae'])\n",
        "\n",
        "    # print(f\"RMSE: {mean_rmse}, R2: {mean_r2}, MAE: {mean_mae}\")\n",
        "    print(f\"RMSE: {mean_rmse}, R² : {mean_r2}, MAE: {mean_mae} ;\\n\\t PARAMS; estimator: {est}, leaning rate: {lg_rt}, gamma: {gam}, max_depth: {max_dep}, min_child_weight: {min_Ch_w}, colsample_b: {col_by}, subsample: {subs}, alpha: {alp}, lambda: {lamb}\")\n",
        "    print(\"-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    return {'loss': mean_r2_n, 'status': STATUS_OK, 'rmse': mean_rmse, 'r2': mean_r2, 'mae': mean_mae}\n",
        "\n",
        "#\t PARAMS; estimator: 900, leaning rate: 0.028358805809222433, max_depth: 10, min_child_weight: 10, colsample_b: 0.6900370414809164, subsample: 0.8886487525524027, alpha: 0.7763249747701536, lambda: 1.6369894164956307\n",
        "space_xgb = {\n",
        "        'n_estimators': hp.quniform('n_estimators', 850, 1100, 1),\n",
        "        'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.03)),\n",
        "        'max_depth': hp.quniform('max_depth', 5, 16, 1),\n",
        "        'min_child_weight': hp.quniform('min_child_weight', 5, 15, 1),\n",
        "        'gamma': hp.uniform('gamma', 0, 1),\n",
        "        #'gamma': hp.loguniform('gamma', np.log(0.001), np.log(0.05)),\n",
        "        'subsample': hp.uniform('subsample', 0.8, 1),\n",
        "        'colsample_bytree': hp.uniform('colsample_bytree', 0.6, 1.0),\n",
        "        # 'alpha': hp.uniform('alpha', 0, 5),\n",
        "        # 'reg_lambda': hp.uniform('reg_lambda', 1, 8)\n",
        "        'alpha': hp.uniform('alpha', 0.5, 0.9),\n",
        "        'reg_lambda': hp.uniform('reg_lambda', 0.5, 1.5)\n",
        "}\n",
        "\n",
        "def objective_lgbm(params):\n",
        "    # Convertir los parámetros a enteros donde sea necesario\n",
        "\n",
        "    params['n_estimators'] = int(params['n_estimators'])\n",
        "    params['max_depth'] = int(params['max_depth'])\n",
        "    params['num_leaves'] = int(params['num_leaves'])\n",
        "    #params['bagging_freq'] = int(params['bagging_freq'])\n",
        "    params['min_child_weight'] = int(params['min_child_weight'])\n",
        "    params['min_child_samples'] = int(params['min_child_samples'])\n",
        "\n",
        "\n",
        "    model = LGBMRegressor(**params, boosting_type='gbdt',\n",
        "                          objective='regression', metric='rmse', n_jobs=-1, verbosity=-1,\n",
        "                          random_state=seed)\n",
        "\n",
        "    est = int(params['n_estimators'])\n",
        "    lg_rt = params['learning_rate']\n",
        "    max_dep = int(params['max_depth'])\n",
        "    min_Ch_w = int(params['min_child_weight'])\n",
        "    nlea = params['num_leaves']\n",
        "    col_by = params['colsample_bytree']\n",
        "    min_Ch_s = params['min_child_samples']\n",
        "    # gam = params['num_leaves']\n",
        "    # alp = params['reg_reg_alpha']\n",
        "    # lamb = params['reg_lambda']\n",
        "\n",
        "    # kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "\n",
        "\n",
        "    # score = -np.mean(cross_val_score(model, X_train, y_train, cv=kfold,\n",
        "    #                                 scoring='r2', n_jobs=-1))\n",
        "\n",
        "    # print(\"Score CV LGBMRegressor: \", score)\n",
        "\n",
        "    # return {'loss': score, 'status': STATUS_OK}\n",
        "\n",
        "    kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "\n",
        "    # Evaluar usando cross_validate para obtener RMSE, R² y MAE\n",
        "    cv_results = cross_validate(model, X_train, y_train, cv=kfold, scoring=scoring, return_train_score=False)\n",
        "\n",
        "    # Calcular la media de cada métrica\n",
        "    #mean_rmse = -np.mean(cv_results['test_rmse'])  # Negativo porque Hyperopt minimiza\n",
        "    mean_rmse = np.mean(cv_results['test_rmse'])  # Negativo porque Hyperopt minimiza\n",
        "    mean_r2 = np.mean(cv_results['test_r2'])\n",
        "    mean_r2_n = -np.mean(cv_results['test_r2'])\n",
        "    mean_mae = np.mean(cv_results['test_mae'])\n",
        "\n",
        "\n",
        "    print(f\"RMSE: {mean_rmse}, R² : {mean_r2}, MAE: {mean_mae} ;\\n\\t PARAMS; estimator: {est}, leaning rate: {lg_rt}, max_depth: {max_dep}, min_child_weight: {min_Ch_w}, num_leaves: {nlea}, colsample_b: {col_by}\")\n",
        "    print(\"-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    return {'loss': mean_r2_n, 'status': STATUS_OK, 'rmse': mean_rmse, 'r2': mean_r2, 'mae': mean_mae}\n",
        "\n",
        "\n",
        "space_lgbm = {\n",
        "    'n_estimators': scope.int(hp.quniform('n_estimators', 1000, 1200, 1)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.03)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 40, 50, 1)),\n",
        "    'num_leaves': scope.int(hp.quniform('num_leaves', 70, 81, 1)),\n",
        "    #'feature_fraction': hp.uniform('feature_fraction', 0.5, 1),\n",
        "    #'bagging_fraction': hp.uniform('bagging_fraction', 0.5, 1),\n",
        "    #'bagging_freq': scope.int(hp.quniform('bagging_freq', 1, 10, 1)),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.080, 0.089),\n",
        "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 10, 15, 1)),\n",
        "    #\n",
        "    'min_child_weight': scope.int(hp.quniform('min_child_weight', 15, 20, 1)),\n",
        "}\n",
        "#Mejores parámetros para LightGBM: {'colsample_bytree': 0.08403093582239003, 'learning_rate': 0.01956317233283169, 'max_depth': 45.0, 'min_child_samples': 12.0, 'min_child_weight': 19.0, 'n_estimators': 1057.0, 'num_leaves': 79.0}\n",
        "def objective_gb(params):\n",
        "\n",
        "    # Convertir los parámetros a enteros donde sea necesario\n",
        "    params['n_estimators'] = int(params['n_estimators'])\n",
        "    params['max_depth'] = int(params['max_depth'])\n",
        "    params['min_samples_split'] = int(params['min_samples_split'])\n",
        "    params['min_samples_leaf'] = int(params['min_samples_leaf'])\n",
        "\n",
        "    model = GradientBoostingRegressor(**params, loss='squared_error', max_features='sqrt', random_state=seed)\n",
        "\n",
        "    est = int(params['n_estimators'])\n",
        "    lg_rt = params['learning_rate']\n",
        "    max_dep = int(params['max_depth'])\n",
        "    min_s_s = int(params['min_samples_split'])\n",
        "    min_s_l = int(params['min_samples_leaf'])\n",
        "    subs = params['subsample']\n",
        "    # col_by = params['colsample_bytree']\n",
        "    # gam = params['gamma']\n",
        "    # alp = params['reg_reg_alpha']\n",
        "    # lamb = params['reg_lambda']\n",
        "\n",
        "    # kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "\n",
        "\n",
        "    # score = -np.mean(cross_val_score(model, X_train, y_train, cv=kfold,\n",
        "    #                                 scoring='r2', n_jobs=-1))\n",
        "\n",
        "    # print(\"Score CV GradientBoostingRegressor: \", score)\n",
        "\n",
        "    # return {'loss': score, 'status': STATUS_OK}\n",
        "\n",
        "    kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "\n",
        "    # Evaluar usando cross_validate para obtener RMSE, R² y MAE\n",
        "    cv_results = cross_validate(model, X_train, y_train, cv=kfold, scoring=scoring, return_train_score=False)\n",
        "\n",
        "    # Calcular la media de cada métrica\n",
        "    #mean_rmse = -np.mean(cv_results['test_rmse'])  # Negativo porque Hyperopt minimiza\n",
        "    mean_rmse = np.mean(cv_results['test_rmse'])  # Negativo porque Hyperopt minimiza\n",
        "    mean_r2 = np.mean(cv_results['test_r2'])\n",
        "    mean_r2_n = -np.mean(cv_results['test_r2'])\n",
        "    mean_mae = np.mean(cv_results['test_mae'])\n",
        "\n",
        "    # print(f\"RMSE: {mean_rmse}, R2: {mean_r2}, MAE: {mean_mae}\")\n",
        "\n",
        "    print(f\"RMSE: {mean_rmse}, R² : {mean_r2}, MAE: {mean_mae} ;\\n\\t PARAMS; estimator: {est}, leaning rate: {lg_rt}, max_depth: {max_dep}, min_samples_split: {min_s_s}, min_samples_leaf: {min_s_l}, subsample: {subs}\")\n",
        "    print(\"-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    return {'loss': mean_r2_n, 'status': STATUS_OK, 'rmse': mean_rmse, 'r2': mean_r2, 'mae': mean_mae}\n",
        "\n",
        "\n",
        "space_gb = {\n",
        "    'n_estimators': scope.int(hp.quniform('n_estimators', 1200, 1400, 10)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.009), np.log(0.03)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 15, 30, 1)),\n",
        "    'subsample': hp.uniform('subsample', 0.5, 0.9),\n",
        "    'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\n",
        "    'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 5, 15, 1))\n",
        "    # 'max_features': hp.choice('max_features', ['sqrt', 'log2']),\n",
        "}\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "IGyQweU-puNq",
        "SGaKvRWNg1ks",
        "DPlsPvKeLvJ_"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "",
      "version": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
